---
title: "Search, Script, Scrape"
---


The concept of web-scraping is simple, if not tedious. And so is civic data.

This is less a programming exercise than a time-management scenario. If the thought of writing 101 separate programs seem so overwhelming

A few caveats



## Getting set up

Please follow these instructions to the letter.

### Create a Github repo named compjour-sss



## How to complete each assignment

### One script for every task

Each task is simple enough to be done in 4 to 10 lines


### Print the answer

The script should execute the `print()` command 



### Mark scripts as "DONE"

For every script that you 




Every task must be



- Is the script's first line `# DONE`?
- Is the script named after its corresponding task number, e.g. `42.py`?
- Does the script leave any intermediary data files behind? It shouldn't.
- Does the script get its data from an official .gov domain (unless the task instructions state otherwise)?
- Does the script download a file greater than 100MB? It shouldn't.
- Does the script print the answer when running it from the command-line?
  
  e.g. `python 42.py`
- Does the script print anything else besides


